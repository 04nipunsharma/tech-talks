{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Delta Lake Supercharges Data Lakes\n",
    "\n",
    "Delta Lake’s transaction log brings high reliability, performance, and ACID compliant transactions to data lakes. But exactly how does it accomplish this?\n",
    "Working through concrete examples, we will take a close look at how the transaction logs are managed and leveraged by Delta to supercharge data lakes.\n",
    "\n",
    "This tutorial notebook was developed using open source Delta on an open source environment.\n",
    "\n",
    "### Environment used to develop and run this notebook\n",
    "* [Centos 7.8](https://www.centos.org/download/)\n",
    "* [Spark 3.0](http://spark.apache.org/docs/latest/)\n",
    "* [Delta Lake 0.7.0](https://github.com/delta-io/delta/releases)\n",
    "* [Scala 2.12](https://www.scala-lang.org/download/2.12.8.html)\n",
    "* [Jupyterlab 2.1.5](https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html)\n",
    "\n",
    "### Installing Delta Lake\n",
    "* [Download 0.7.0 jar file](https://mvnrepository.com/artifact/io.delta/delta-core_2.12/0.7.0)\n",
    "* Move jar file to $SPARK_HOME/jars\n",
    "* More Details here: [Setting up Apache Spark with Delta](https://docs.delta.io/latest/quick-start.html#set-up-apache-spark-with-delta-lake)\n",
    "\n",
    "### Source Data for this notebook\n",
    "\n",
    "The data used in this tutorial is a modified version of the public data from [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Online+Retail#). This dataset contains transactional data from a UK online retailer and it spans January 12, 2010 to September 12, 2011. For a full view of the data please view the data dictionary available [here](http://archive.ics.uci.edu/ml/datasets/Online+Retail#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"https://docs.delta.io/latest/_static/delta-lake-logo.png\" width=300/>  \n",
    "\n",
    "An open-source storage format that brings ACID transactions to Apache Spark™ and big data workloads.\n",
    "\n",
    "* **Open format**: Stored as Parquet format in blob storage.\n",
    "* **ACID Transactions**: Ensures data integrity and read consistency with complex, concurrent data pipelines.\n",
    "* **Schema Enforcement and Evolution**: Ensures data cleanliness by blocking writes with unexpected.\n",
    "* **Audit History**: History of all the operations that happened in the table.\n",
    "* **Time Travel**: Query previous versions of the table by time or version number.\n",
    "* **Deletes and upserts**: Supports deleting and upserting into tables with programmatic APIs.\n",
    "* **Scalable Metadata management**: Able to handle millions of files are scaling the metadata operations with Spark.\n",
    "* **Unified Batch and Streaming Source and Sink**: A table in Delta Lake is both a batch table, as well as a streaming source and sink. Streaming data ingest, batch historic backfill, and interactive queries all just work out of the box.\n",
    "\n",
    "<img src=\"https://www.evernote.com/l/AAF4VIILJtFNZLuvZjGGhZTr2H6Z0wh6rOYB/image.png\" width=800px align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup, Helpers, Config & APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Classes\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum, expr, rand, when, count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session & configure it for Delta Lake version 0.7.0\n",
    "\n",
    "# Load delta library - .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:0.7.0\")\n",
    "# Enable sql (Delta Lake specific) support within Apache Spark - .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "# Enable integration with Catalog APIs (since 3.0) - .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DeltaLake Transaction Logs\") \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:0.7.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Main class for programmatically intereacting with Delta Tables.\n",
    "from delta.tables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configurations for our Spark Session\n",
    "# Adjust to your environment, e.g # cores on cluster\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 4)\n",
    "spark.conf.set(\"spark.default.parallelism\", 4)\n",
    "# POO spark.conf.set(\"spark.databricks.delta.snapshotPartitions\", 4)\n",
    "# POO https://stackoverflow.com/questions/61635681/what-is-spark-databricks-delta-snapshotpartitions-configuration-used-for-in-delt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load helper functions\n",
    "\n",
    "%run Helpers.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted path /home/spark/data/delta/online_retail_data\n",
      "Deleted path /home/spark/data/parquet/online_retail_data\n"
     ]
    }
   ],
   "source": [
    "# Source data\n",
    "# Change paths to match your environment!\n",
    "\n",
    "inputPath    = \"/home/spark/data/source/\"\n",
    "sourceData   = inputPath + \"online-retail-dataset.csv\"\n",
    "\n",
    "# Base location for all saved data\n",
    "basePath     = \"/home/spark/data\" \n",
    "\n",
    "# Path for Parquet formatted data\n",
    "parquetPath  = basePath + \"/parquet/online_retail_data\"\n",
    "\n",
    "# Path for Delta formatted data\n",
    "deltaPath    = basePath + \"/delta/online_retail_data\"\n",
    "deltaLogPath = deltaPath + \"/_delta_log\"\n",
    "\n",
    "# Clean up from last run.\n",
    "! rm -Rf $deltaPath 2>/dev/null\n",
    "print(\"Deleted path \" + deltaPath)\n",
    "\n",
    "! rm -Rf $parquetPath 2>/dev/null\n",
    "print(\"Deleted path \" + parquetPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Stage Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Dataset is present.\n",
      "\n",
      "File [/home/spark/data/source/online-retail-dataset.csv] is ['43'] MB in size.\n"
     ]
    }
   ],
   "source": [
    "# Data sourced from \"Spark - The Definitive Guide\", located at: https://github.com/databricks/Spark-The-Definitive-Guide\n",
    "# Data origin: http://archive.ics.uci.edu/ml/datasets/Online+Retail\n",
    "import os.path\n",
    "\n",
    "file_exists = os.path.isfile(f'{sourceData}')\n",
    " \n",
    "if not file_exists:\n",
    "    print(\"-> Downloading dataset.\")\n",
    "    os.system(\"curl https://raw.githubusercontent.com/databricks/Spark-The-Definitive-Guide/master/data/retail-data/all/online-retail-dataset.csv -o /home/spark/data/source/online-retail-dataset.csv\")\n",
    "    file_exists = os.path.isfile(f'{sourceData}')\n",
    "    \n",
    "if file_exists:\n",
    "    print(\"-> Dataset is present.\\n\")\n",
    "    \n",
    "    fileSize = ! du -m \"$sourceData\" | cut -f1 # Posix compliant\n",
    "    print(f\"File [{sourceData}] is {fileSize} MB in size.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Schema for Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,CustomerID,Country\n",
      "536365,85123A,WHITE HANGING HEART T-LIGHT HOLDER,6,12/1/2010 8:26,2.55,17850,United Kingdom\n",
      "536365,71053,WHITE METAL LANTERN,6,12/1/2010 8:26,3.39,17850,United Kingdom\n",
      "536365,84406B,CREAM CUPID HEARTS COAT HANGER,8,12/1/2010 8:26,2.75,17850,United Kingdom\n",
      "536365,84029G,KNITTED UNION FLAG HOT WATER BOTTLE,6,12/1/2010 8:26,3.39,17850,United Kingdom\n"
     ]
    }
   ],
   "source": [
    "# Let's take a peek at the data in text file format\n",
    "! head -n 5 $sourceData 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide schema for source data\n",
    "# Schema source: http://archive.ics.uci.edu/ml/datasets/Online+Retail#\n",
    "\n",
    "# SQL DDL method\n",
    "schemaDDL = \"\"\"InvoiceNo Integer, StockCode String, Description String, Quantity Integer, \n",
    "               InvoiceDate String, UnitPrice Double, CustomerID Integer, Country String \"\"\"\n",
    "\n",
    "\n",
    "# You could also use the StructType method.\n",
    "# Libraries needed to define schemas\n",
    "# from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType, StringType\n",
    "\n",
    "#inputSchema = StructType([\n",
    "#  StructField(\"InvoiceNo\", IntegerType(), True),\n",
    "#  StructField(\"StockCode\", StringType(), True),\n",
    "#  StructField(\"Description\", StringType(), True),\n",
    "#  StructField(\"Quantity\", IntegerType(), True),\n",
    "#  StructField(\"InvoiceDate\", StringType(), True),\n",
    "#  StructField(\"UnitPrice\", DoubleType(), True),\n",
    "#  StructField(\"CustomerID\", IntegerType(), True),\n",
    "#  StructField(\"Country\", StringType(), True)\n",
    "#])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count: 541909 Partition Count: 4\n"
     ]
    }
   ],
   "source": [
    "# Create retail sales data dataframe\n",
    "\n",
    "rawSalesDataDF = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\",\"true\")\n",
    "    .schema(schemaDDL)\n",
    "    .load(sourceData)\n",
    ")\n",
    "\n",
    "# Count rows and partitions\n",
    "rowCount = rawSalesDataDF.count() \n",
    "partCount = rawSalesDataDF.rdd.getNumPartitions()\n",
    "\n",
    "print(f'Row Count: {rowCount} Partition Count: {partCount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with null values\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|     9291|        0|       1454|       0|          0|        0|    135080|      0|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identify columns with null values\n",
    "\n",
    "print(\"Columns with null values\")\n",
    "rawSalesDataDF.select([count(when(col(c).isNull(), c)).alias(c) for c in rawSalesDataDF.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null values\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|        0|        0|          0|       0|          0|        0|         0|      0|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n",
      " RowsRemoved: 143985\n",
      " Final Row Count: 397924\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where important columns are null. In our case: InvoiceNo and CustomerID\n",
    "\n",
    "cleanSalesDataDF = rawSalesDataDF.where(col(\"InvoiceNo\").isNotNull() & col(\"CustomerID\").isNotNull())\n",
    "cleanSalesDataCount = cleanSalesDataDF.count()\n",
    "# POO cleanSalesDataDF = cleanSalesDataDF.where(col(\"CustomerID\").isNotNull())\n",
    "\n",
    "# All rows with null values should be gone\n",
    "print(\"null values\")\n",
    "cleanSalesDataDF.select([count(when(col(c).isNull(), c)).alias(c) for c in rawSalesDataDF.columns]).show()\n",
    "\n",
    "print(f' RowsRemoved: {rowCount-cleanSalesDataCount}\\n Final Row Count: {cleanSalesDataCount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count: 99226 Partition Count: 4\n"
     ]
    }
   ],
   "source": [
    "# Define new dataframe based on cleansed data but only use a subset of the data\n",
    "\n",
    "# Random sample of 25%, with seed and without replacement\n",
    "retailSalesData1 = cleanSalesDataDF.sample(withReplacement=False, fraction=.25, seed=75)\n",
    "\n",
    "# Count rows and partitions\n",
    "rowCount = retailSalesData1.count() \n",
    "partCount = retailSalesData1.rdd.getNumPartitions()\n",
    "\n",
    "print(f'Row Count: {rowCount} Partition Count: {partCount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate   |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n",
      "|536365   |21730    |GLASS STAR FROSTED T-LIGHT HOLDER  |6       |12/1/2010 8:26|4.25     |17850     |United Kingdom|\n",
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Peek at the dataframe\n",
    "\n",
    "retailSalesData1.show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIVE Metastore Database Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|deltademo|\n",
      "| louis_db|\n",
      "+---------+\n",
      "\n",
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|         deltademo|\n",
      "+------------------+\n",
      "\n",
      "+-------------------------+----------------------------------------------------------------------------------------+\n",
      "|database_description_item|database_description_value                                                              |\n",
      "+-------------------------+----------------------------------------------------------------------------------------+\n",
      "|Database Name            |deltademo                                                                               |\n",
      "|Comment                  |                                                                                        |\n",
      "|Location                 |file:/home/spark/projects/spark3-projects/spark3-playground/spark-warehouse/deltademo.db|\n",
      "|Owner                    |spark                                                                                   |\n",
      "+-------------------------+----------------------------------------------------------------------------------------+\n",
      "\n",
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create database to hold demo objects\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS deltademo\")\n",
    "spark.sql(\"SHOW DATABASES\").show()\n",
    "\n",
    "# Current DB should be deltademo\n",
    "spark.sql(\"USE deltademo\")\n",
    "spark.sql(\"select current_database()\").show()\n",
    "spark.sql(\"DESCRIBE DATABASE deltademo\").show(truncate = False)\n",
    "\n",
    "# Clean-up from last run\n",
    "spark.sql(\"DROP TABLE IF EXISTS SalesParquetFormat\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS SalesDeltaFormat\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS tbl_CheckpointFile\")\n",
    "spark.sql(\"show tables\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data as a table in Parquet format\n",
    "\n",
    "retailSalesData1.write.saveAsTable('SalesParquetFormat', format='parquet', mode='overwrite',path=parquetPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='salesparquetformat', database='deltademo', description=None, tableType='EXTERNAL', isTemporary=False)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's peek into the catalog and verify that our table was created\n",
    "\n",
    "spark.catalog.listTables()\n",
    "\n",
    "# SQL method - not as informative\n",
    "# spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195KB    2020-08-25 17:31:56  part-00003-f64442fa-fc93-489a-b228-a99e45a30e88-c000.snappy.parquet\n",
      "282KB    2020-08-25 17:31:56  part-00000-f64442fa-fc93-489a-b228-a99e45a30e88-c000.snappy.parquet\n",
      "312KB    2020-08-25 17:31:56  part-00001-f64442fa-fc93-489a-b228-a99e45a30e88-c000.snappy.parquet\n",
      "314KB    2020-08-25 17:31:56  part-00002-f64442fa-fc93-489a-b228-a99e45a30e88-c000.snappy.parquet\n",
      "\n",
      "Number of file/s: 4 | Total size: 1.2M\n"
     ]
    }
   ],
   "source": [
    "# Files and size on disk\n",
    "\n",
    "files_in_dir(parquetPath, \"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                     |comment|\n",
      "+----------------------------+--------------------------------------------------------------+-------+\n",
      "|InvoiceNo                   |int                                                           |null   |\n",
      "|StockCode                   |string                                                        |null   |\n",
      "|Description                 |string                                                        |null   |\n",
      "|Quantity                    |int                                                           |null   |\n",
      "|InvoiceDate                 |string                                                        |null   |\n",
      "|UnitPrice                   |double                                                        |null   |\n",
      "|CustomerID                  |int                                                           |null   |\n",
      "|Country                     |string                                                        |null   |\n",
      "|                            |                                                              |       |\n",
      "|# Detailed Table Information|                                                              |       |\n",
      "|Database                    |deltademo                                                     |       |\n",
      "|Table                       |salesparquetformat                                            |       |\n",
      "|Owner                       |spark                                                         |       |\n",
      "|Created Time                |Tue Aug 25 17:31:57 EDT 2020                                  |       |\n",
      "|Last Access                 |UNKNOWN                                                       |       |\n",
      "|Created By                  |Spark 3.0.0                                                   |       |\n",
      "|Type                        |EXTERNAL                                                      |       |\n",
      "|Provider                    |parquet                                                       |       |\n",
      "|Statistics                  |1129731 bytes                                                 |       |\n",
      "|Location                    |file:/home/spark/data/parquet/online_retail_data              |       |\n",
      "|Serde Library               |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe   |       |\n",
      "|InputFormat                 |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat|       |\n",
      "+----------------------------+--------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe extended SalesParquetFormat\").show(100,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------------------------+--------+---------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                 |Quantity|InvoiceDate    |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+----------------------------+--------+---------------+---------+----------+--------------+\n",
      "|563016   |21497    |FANCY FONTS BIRTHDAY WRAP   |25      |8/11/2011 12:44|0.42     |15358     |United Kingdom|\n",
      "|563016   |22993    |SET OF 4 PANTRY JELLY MOULDS|12      |8/11/2011 12:44|1.25     |15358     |United Kingdom|\n",
      "|563016   |22961    |JAM MAKING SET PRINTED      |12      |8/11/2011 12:44|1.45     |15358     |United Kingdom|\n",
      "+---------+---------+----------------------------+--------+---------------+---------+----------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Spark SQL to query the newly created table\n",
    "\n",
    "spark.sql(\"SELECT * FROM SalesParquetFormat;\").show(3, truncate = False)\n",
    "\n",
    "# You can directly query the directory too.\n",
    "# spark.sql(f\"SELECT * FROM parquet.`{parquetPath}` limit 5 \").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add one row of data to the table\n",
    "# Parquet being immutable necessitates the creation of an additional Parquet file\n",
    "\n",
    "spark.sql(\"\"\" \n",
    "             insert into SalesParquetFormat\n",
    "              values(963316, 2291, \"WORLD'S BEST JAM MAKING SET\", 5, \"08/13/2011 07:58\", 1.45, 15358, \"United Kingdom\")\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195KB    2020-08-25 17:31:56  part-00003-f64442fa-fc93-489a-b228-a99e45a30e88-c000.snappy.parquet\n",
      "282KB    2020-08-25 17:31:56  part-00000-f64442fa-fc93-489a-b228-a99e45a30e88-c000.snappy.parquet\n",
      "312KB    2020-08-25 17:31:56  part-00001-f64442fa-fc93-489a-b228-a99e45a30e88-c000.snappy.parquet\n",
      "314KB    2020-08-25 17:31:56  part-00002-f64442fa-fc93-489a-b228-a99e45a30e88-c000.snappy.parquet\n",
      "2KB      2020-08-25 17:31:58  part-00000-ce551c38-ae92-4fe3-bcb8-96b880604dd0-c000.snappy.parquet\n",
      "\n",
      "Number of file/s: 5 | Total size: 1.2M\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(parquetPath, \"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a peek at the new file\n",
    "\n",
    "# spark.read.load(f\"{parquetPath}/part-00000-e4bffb32-c1ed-4871-b88c-a9ae1a68635e-c000.snappy.parquet\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above we saw how to create a table structure using Parquet as the underlying data.<br>\n",
    "- Using sql we were able to query the table and even insert new data using sql.<br>\n",
    "- However, no history was kept of these operations.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://files.training.databricks.com/images/adbcore/AAFxQkg_SzRC06GvVeatDBnNbDL7wUUgCg4B.png\" alt=\"Delta Lake\" width=\"600\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------------------------+--------+---------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                 |Quantity|InvoiceDate    |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+----------------------------+--------+---------------+---------+----------+--------------+\n",
      "|563016   |21497    |FANCY FONTS BIRTHDAY WRAP   |25      |8/11/2011 12:44|0.42     |15358     |United Kingdom|\n",
      "|563016   |22993    |SET OF 4 PANTRY JELLY MOULDS|12      |8/11/2011 12:44|1.25     |15358     |United Kingdom|\n",
      "|563016   |22961    |JAM MAKING SET PRINTED      |12      |8/11/2011 12:44|1.45     |15358     |United Kingdom|\n",
      "+---------+---------+----------------------------+--------+---------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save retailSalesData1 to Delta\n",
    "\n",
    "#T1A4T4\n",
    "retailSalesData1.write.mode(\"overwrite\").format(\"delta\").save(deltaPath)\n",
    "\n",
    "# Query delta directory directly\n",
    "spark.sql(f\"SELECT * FROM delta.`{deltaPath}` limit 3 \").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable for a path based Delta table\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark, deltaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### HISTORY ########\n",
      "+---+-------------------+---------+--------------------------------------+------------------------------------------------------------------+\n",
      "|ver|timestamp          |operation|operationParameters                   |operationMetrics                                                  |\n",
      "+---+-------------------+---------+--------------------------------------+------------------------------------------------------------------+\n",
      "|0  |2020-08-25 17:32:01|WRITE    |[mode -> Overwrite, partitionBy -> []]|[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]|\n",
      "+---+-------------------+---------+--------------------------------------+------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"####### HISTORY ########\")\n",
    "\n",
    "# Observe history of actions taken on a Delta table\n",
    "history = deltaTable.history().select('version','timestamp','operation', 'operationParameters', \\\n",
    "                                      'operationMetrics') \\\n",
    "                              .withColumnRenamed(\"version\", \"ver\")\n",
    "\n",
    "history.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195KB    2020-08-25 17:31:59  part-00003-8aedf44b-df4f-4194-8e0e-69b3790478ad-c000.snappy.parquet\n",
      "312KB    2020-08-25 17:32:00  part-00001-985a76da-9b3b-4b6d-8596-20fe7ee8e91d-c000.snappy.parquet\n",
      "282KB    2020-08-25 17:32:00  part-00000-023a68c6-9fc5-4f66-9163-7a517a09b2bc-c000.snappy.parquet\n",
      "314KB    2020-08-25 17:32:00  part-00002-8aafd9bb-16a7-4c09-aa34-f217d82cde16-c000.snappy.parquet\n",
      "\n",
      "Number of file/s: 4 | Total size: 1.2M\n"
     ]
    }
   ],
   "source": [
    "# files and size on disk\n",
    "\n",
    "files_in_dir(deltaPath, \"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.1M\n",
      "drwxrwxr-x. 2 spark spark   39 Aug 25 17:32 _delta_log\n",
      "-rw-r--r--. 1 spark spark 315K Aug 25 17:32 part-00002-8aafd9bb-16a7-4c09-aa34-f217d82cde16-c000.snappy.parquet\n",
      "-rw-r--r--. 1 spark spark 282K Aug 25 17:32 part-00000-023a68c6-9fc5-4f66-9163-7a517a09b2bc-c000.snappy.parquet\n",
      "-rw-r--r--. 1 spark spark 313K Aug 25 17:32 part-00001-985a76da-9b3b-4b6d-8596-20fe7ee8e91d-c000.snappy.parquet\n",
      "-rw-r--r--. 1 spark spark 196K Aug 25 17:31 part-00003-8aedf44b-df4f-4194-8e0e-69b3790478ad-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "# Notice the sub-directory \"_delta_log\"\n",
    "! ls -thl $deltaPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-25 17:32:01  00000000000000000000.json\n",
      "\n",
      "Number of file/s: 1 | Total size: 4.0K\n"
     ]
    }
   ],
   "source": [
    "# # files and size on disk\n",
    "# We can see that parquet files were added but now there is a trx log\n",
    "\n",
    "files_in_dir(deltaLogPath, \"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(add=None, commitInfo=Row(isBlindAppend=False, operation='WRITE', operationMetrics=Row(numFiles='4', numOutputBytes='1129731', numOutputRows='99226'), operationParameters=Row(mode='Overwrite', partitionBy='[]'), timestamp=1598391121653), metaData=None, protocol=None),\n",
       " Row(add=None, commitInfo=None, metaData=None, protocol=Row(minReaderVersion=1, minWriterVersion=2)),\n",
       " Row(add=None, commitInfo=None, metaData=Row(createdTime=1598391119308, format=Row(provider='parquet'), id='e1ff22de-5098-4cd6-9208-094028d347ab', partitionColumns=[], schemaString='{\"type\":\"struct\",\"fields\":[{\"name\":\"InvoiceNo\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"StockCode\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Description\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Quantity\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"InvoiceDate\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"UnitPrice\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"CustomerID\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Country\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}'), protocol=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391120000, path='part-00000-023a68c6-9fc5-4f66-9163-7a517a09b2bc-c000.snappy.parquet', size=288465), commitInfo=None, metaData=None, protocol=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391120000, path='part-00001-985a76da-9b3b-4b6d-8596-20fe7ee8e91d-c000.snappy.parquet', size=319754), commitInfo=None, metaData=None, protocol=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391120000, path='part-00002-8aafd9bb-16a7-4c09-aa34-f217d82cde16-c000.snappy.parquet', size=321712), commitInfo=None, metaData=None, protocol=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391119000, path='part-00003-8aedf44b-df4f-4194-8e0e-69b3790478ad-c000.snappy.parquet', size=199800), commitInfo=None, metaData=None, protocol=None)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a peek inside the trx log\n",
    "\n",
    "spark.read.format(\"json\").load(deltaLogPath + \"/00000000000000000000.json\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99149"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with fraction of original data.\n",
    "# Random sample of 25%, with seed and without replacement\n",
    "\n",
    "retailSalesData2 = cleanSalesDataDF.sample(withReplacement=False, fraction=.25, seed=31)\n",
    "retailSalesData2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to our Delta Lake table by appending retailSalesData2\n",
    "\n",
    "#T2A4T8\n",
    "retailSalesData2.write.mode(\"append\").format(\"delta\").save(deltaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### HISTORY ########\n",
      "+---+-------------------+---------+--------------------------------------+------------------------------------------------------------------+\n",
      "|ver|timestamp          |operation|operationParameters                   |operationMetrics                                                  |\n",
      "+---+-------------------+---------+--------------------------------------+------------------------------------------------------------------+\n",
      "|1  |2020-08-25 17:32:08|WRITE    |[mode -> Append, partitionBy -> []]   |[numFiles -> 4, numOutputBytes -> 1125004, numOutputRows -> 99149]|\n",
      "|0  |2020-08-25 17:32:01|WRITE    |[mode -> Overwrite, partitionBy -> []]|[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]|\n",
      "+---+-------------------+---------+--------------------------------------+------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"####### HISTORY ########\")\n",
    "\n",
    "# Observe history of actions taken on a Delta table\n",
    "# Reference for full history schema: https://docs.delta.io/latest/delta-utility.html\n",
    "history = deltaTable.history().select('version','timestamp','operation', 'operationParameters', \\\n",
    "                                      'operationMetrics') \\\n",
    "                              .withColumnRenamed(\"version\", \"ver\")\n",
    "\n",
    "history.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195KB    2020-08-25 17:31:59  part-00003-8aedf44b-df4f-4194-8e0e-69b3790478ad-c000.snappy.parquet\n",
      "312KB    2020-08-25 17:32:00  part-00001-985a76da-9b3b-4b6d-8596-20fe7ee8e91d-c000.snappy.parquet\n",
      "282KB    2020-08-25 17:32:00  part-00000-023a68c6-9fc5-4f66-9163-7a517a09b2bc-c000.snappy.parquet\n",
      "314KB    2020-08-25 17:32:00  part-00002-8aafd9bb-16a7-4c09-aa34-f217d82cde16-c000.snappy.parquet\n",
      "193KB    2020-08-25 17:32:07  part-00003-fe773de7-76c0-4880-b4a5-e48275f6f25c-c000.snappy.parquet\n",
      "315KB    2020-08-25 17:32:07  part-00002-ae418f88-33ad-4119-9906-53feef7a5557-c000.snappy.parquet\n",
      "281KB    2020-08-25 17:32:08  part-00000-4d0d0177-abdf-48aa-8daf-62b696c3ed50-c000.snappy.parquet\n",
      "310KB    2020-08-25 17:32:08  part-00001-cb2d19ab-ac6a-4db7-974f-f7ebe111dc20-c000.snappy.parquet\n",
      "\n",
      "Number of file/s: 8 | Total size: 2.3M\n"
     ]
    }
   ],
   "source": [
    "# Data Files and size on disk\n",
    "\n",
    "files_in_dir(deltaPath, \"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-25 17:32:01  00000000000000000000.json\n",
      "938B     2020-08-25 17:32:08  00000000000000000001.json\n",
      "\n",
      "Number of file/s: 2 | Total size: 8.0K\n"
     ]
    }
   ],
   "source": [
    "# Transaction logs and size on disk\n",
    "\n",
    "files_in_dir(deltaLogPath, \"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(add=None, commitInfo=Row(isBlindAppend=True, operation='WRITE', operationMetrics=Row(numFiles='4', numOutputBytes='1125004', numOutputRows='99149'), operationParameters=Row(mode='Append', partitionBy='[]'), readVersion=0, timestamp=1598391128079)),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391128000, path='part-00000-4d0d0177-abdf-48aa-8daf-62b696c3ed50-c000.snappy.parquet', size=287535), commitInfo=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391128000, path='part-00001-cb2d19ab-ac6a-4db7-974f-f7ebe111dc20-c000.snappy.parquet', size=317603), commitInfo=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391127000, path='part-00002-ae418f88-33ad-4119-9906-53feef7a5557-c000.snappy.parquet', size=322207), commitInfo=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391127000, path='part-00003-fe773de7-76c0-4880-b4a5-e48275f6f25c-c000.snappy.parquet', size=197659), commitInfo=None)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek inside the new transaction log\n",
    "\n",
    "logDF = spark.read.format(\"json\").load(deltaLogPath + \"/00000000000000000001.json\")\n",
    "logDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create SQL table to make life easier\n",
    "# Stick with SQL from here on out, where possible.\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    DROP TABLE IF EXISTS SalesDeltaFormat\n",
    "  \"\"\")\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE SalesDeltaFormat\n",
    "    USING DELTA\n",
    "    LOCATION '{}'\n",
    "  \"\"\".format(deltaPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='salesdeltaformat', database='deltademo', description=None, tableType='EXTERNAL', isTemporary=False),\n",
       " Table(name='salesparquetformat', database='deltademo', description=None, tableType='EXTERNAL', isTemporary=False)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's peek into the catalog and verify that our table was created.\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----------------------------------------------+-------+\n",
      "|col_name                    |data_type                                     |comment|\n",
      "+----------------------------+----------------------------------------------+-------+\n",
      "|InvoiceNo                   |int                                           |       |\n",
      "|StockCode                   |string                                        |       |\n",
      "|Description                 |string                                        |       |\n",
      "|Quantity                    |int                                           |       |\n",
      "|InvoiceDate                 |string                                        |       |\n",
      "|UnitPrice                   |double                                        |       |\n",
      "|CustomerID                  |int                                           |       |\n",
      "|Country                     |string                                        |       |\n",
      "|                            |                                              |       |\n",
      "|# Partitioning              |                                              |       |\n",
      "|Not partitioned             |                                              |       |\n",
      "|                            |                                              |       |\n",
      "|# Detailed Table Information|                                              |       |\n",
      "|Name                        |deltademo.salesdeltaformat                    |       |\n",
      "|Location                    |file:/home/spark/data/delta/online_retail_data|       |\n",
      "|Provider                    |delta                                         |       |\n",
      "|Table Properties            |[]                                            |       |\n",
      "+----------------------------+----------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe extended SalesDeltaFormat\").show(100, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Invoice # => 563164\n"
     ]
    }
   ],
   "source": [
    "# Let's find a Invoice with only 1 count and use it to test DML.\n",
    "oneRandomInvoice = spark.sql(\"\"\" SELECT InvoiceNo, count(*)\n",
    "                                 FROM SalesDeltaFormat\n",
    "                                 GROUP BY InvoiceNo\n",
    "                                 ORDER BY 2 asc\n",
    "                                 LIMIT 1\n",
    "                             \"\"\").collect()[0][0]\n",
    "\n",
    "print(f\"Random Invoice # => {oneRandomInvoice}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+---------+---------+-----------------+--------+---------------+---------+----------+--------------+\n",
      "|FileName                                                           |InvoiceNo|StockCode|Description      |Quantity|InvoiceDate    |UnitPrice|CustomerID|Country       |\n",
      "+-------------------------------------------------------------------+---------+---------+-----------------+--------+---------------+---------+----------+--------------+\n",
      "|part-00002-ae418f88-33ad-4119-9906-53feef7a5557-c000.snappy.parquet|563164   |23089    |GLASS BON BON JAR|144     |8/12/2011 12:18|1.45     |16013     |United Kingdom|\n",
      "+-------------------------------------------------------------------+---------+---------+-----------------+--------+---------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Before DML (insert)\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "              SELECT SUBSTRING(input_file_name(), -67, 67) AS FileName,\n",
    "                     * FROM SalesDeltaFormat \n",
    "              WHERE InvoiceNo = {oneRandomInvoice}\n",
    "           \"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add some data to our table\n",
    "\n",
    "#T3A1T9\n",
    "spark.sql(f\"\"\"\n",
    "               INSERT INTO SalesDeltaFormat\n",
    "               VALUES({oneRandomInvoice}, 2291, \"WORLD'S BEST JAM MAKING SET\", 5, \"08/13/2011 07:58\", 1.45, 15358, \"France\");\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-25 17:32:01  00000000000000000000.json\n",
      "938B     2020-08-25 17:32:08  00000000000000000001.json\n",
      "410B     2020-08-25 17:32:11  00000000000000000002.json\n",
      "\n",
      "Number of file/s: 3 | Total size: 12K\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaLogPath,\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(add=None, commitInfo=Row(isBlindAppend=True, operation='WRITE', operationMetrics=Row(numFiles='1', numOutputBytes='2369', numOutputRows='1'), operationParameters=Row(mode='Append', partitionBy='[]'), readVersion=1, timestamp=1598391131747)),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391131000, path='part-00000-ec6e161b-f530-4474-ab02-f0083d596f18-c000.snappy.parquet', size=2369), commitInfo=None)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Schema details: https://docs.delta.io/latest/delta-utility.html\n",
    "\n",
    "logDF = spark.read.format(\"json\").load(deltaLogPath + \"/00000000000000000002.json\")\n",
    "#dfLog.printSchema()\n",
    "logDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+--------------+\n",
      "|FileName                                                           |InvoiceNo|StockCode|Description                |Quantity|InvoiceDate     |UnitPrice|CustomerID|Country       |\n",
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+--------------+\n",
      "|part-00002-ae418f88-33ad-4119-9906-53feef7a5557-c000.snappy.parquet|563164   |23089    |GLASS BON BON JAR          |144     |8/12/2011 12:18 |1.45     |16013     |United Kingdom|\n",
      "|part-00000-ec6e161b-f530-4474-ab02-f0083d596f18-c000.snappy.parquet|563164   |2291     |WORLD'S BEST JAM MAKING SET|5       |08/13/2011 07:58|1.45     |15358     |France        |\n",
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After DML (insert)\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "              SELECT SUBSTRING(input_file_name(), -67, 67) AS FileName, *\n",
    "                     FROM SalesDeltaFormat \n",
    "                     WHERE InvoiceNo = {oneRandomInvoice}\n",
    "           \"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/delta-io/delta/blob/master/examples/python/quickstart.py\n",
    "# Update one record\n",
    "\n",
    "#T4A2T11\n",
    "spark.sql(f\"\"\"\n",
    "              UPDATE SalesDeltaFormat\n",
    "              SET Quantity = Quantity + 1000\n",
    "              WHERE InvoiceNo = {oneRandomInvoice}\n",
    "           \"\"\")\n",
    "\n",
    "#deltaTable.update(\n",
    "#    condition=(\"InvoiceNo = oneInvoice\"),\n",
    "#    set={\"Quantity\": expr(\"Quantity + 1000\")}\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+--------------+\n",
      "|FileName                                                           |InvoiceNo|StockCode|Description                |Quantity|InvoiceDate     |UnitPrice|CustomerID|Country       |\n",
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+--------------+\n",
      "|part-00000-591907ef-834f-41f5-a7f5-35928ff8aefa-c000.snappy.parquet|563164   |23089    |GLASS BON BON JAR          |1144    |8/12/2011 12:18 |1.45     |16013     |United Kingdom|\n",
      "|part-00001-8488bed6-f43f-4cd1-9053-79ccf4ec5f1a-c000.snappy.parquet|563164   |2291     |WORLD'S BEST JAM MAKING SET|1005    |08/13/2011 07:58|1.45     |15358     |France        |\n",
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After Update\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "              SELECT \n",
    "              SUBSTRING(input_file_name(), -67, 67) AS FileName, *\n",
    "              FROM SalesDeltaFormat \n",
    "              WHERE InvoiceNo = {oneRandomInvoice}\n",
    "           \"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### HISTORY ########\n",
      "+---+---------+----------------------------------------+---------------------------------------------------------------------------------------+\n",
      "|ver|operation|operationParameters                     |operationMetrics                                                                       |\n",
      "+---+---------+----------------------------------------+---------------------------------------------------------------------------------------+\n",
      "|3  |UPDATE   |[predicate -> (InvoiceNo#2648 = 563164)]|[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 2, numCopiedRows -> 29509]|\n",
      "|2  |WRITE    |[mode -> Append, partitionBy -> []]     |[numFiles -> 1, numOutputBytes -> 2369, numOutputRows -> 1]                            |\n",
      "|1  |WRITE    |[mode -> Append, partitionBy -> []]     |[numFiles -> 4, numOutputBytes -> 1125004, numOutputRows -> 99149]                     |\n",
      "|0  |WRITE    |[mode -> Overwrite, partitionBy -> []]  |[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]                     |\n",
      "+---+---------+----------------------------------------+---------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"####### HISTORY ########\")\n",
    "\n",
    "# Show which datafile was removed.\n",
    "\n",
    "# Observe history of actions taken on a Delta table\n",
    "# spark.sql not supported in 0.7.0 OSS Delta\n",
    "history = deltaTable.history().select('version','operation', 'operationParameters', \\\n",
    "                                      'operationMetrics') \\\n",
    "                              .withColumnRenamed(\"version\", \"ver\")\n",
    "\n",
    "history.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195KB    2020-08-25 17:31:59  part-00003-8aedf44b-df4f-4194-8e0e-69b3790478ad-c000.snappy.parquet\n",
      "312KB    2020-08-25 17:32:00  part-00001-985a76da-9b3b-4b6d-8596-20fe7ee8e91d-c000.snappy.parquet\n",
      "282KB    2020-08-25 17:32:00  part-00000-023a68c6-9fc5-4f66-9163-7a517a09b2bc-c000.snappy.parquet\n",
      "314KB    2020-08-25 17:32:00  part-00002-8aafd9bb-16a7-4c09-aa34-f217d82cde16-c000.snappy.parquet\n",
      "193KB    2020-08-25 17:32:07  part-00003-fe773de7-76c0-4880-b4a5-e48275f6f25c-c000.snappy.parquet\n",
      "315KB    2020-08-25 17:32:07  part-00002-ae418f88-33ad-4119-9906-53feef7a5557-c000.snappy.parquet\n",
      "281KB    2020-08-25 17:32:08  part-00000-4d0d0177-abdf-48aa-8daf-62b696c3ed50-c000.snappy.parquet\n",
      "310KB    2020-08-25 17:32:08  part-00001-cb2d19ab-ac6a-4db7-974f-f7ebe111dc20-c000.snappy.parquet\n",
      "2KB      2020-08-25 17:32:11  part-00000-ec6e161b-f530-4474-ab02-f0083d596f18-c000.snappy.parquet\n",
      "2KB      2020-08-25 17:32:14  part-00001-8488bed6-f43f-4cd1-9053-79ccf4ec5f1a-c000.snappy.parquet\n",
      "315KB    2020-08-25 17:32:14  part-00000-591907ef-834f-41f5-a7f5-35928ff8aefa-c000.snappy.parquet\n",
      "\n",
      "Number of file/s: 11 | Total size: 2.6M\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaPath, \"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-25 17:32:01  00000000000000000000.json\n",
      "938B     2020-08-25 17:32:08  00000000000000000001.json\n",
      "410B     2020-08-25 17:32:11  00000000000000000002.json\n",
      "902B     2020-08-25 17:32:14  00000000000000000003.json\n",
      "\n",
      "Number of file/s: 4 | Total size: 16K\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaLogPath,\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(add=None, commitInfo=Row(isBlindAppend=False, operation='UPDATE', operationMetrics=Row(numAddedFiles='2', numCopiedRows='29509', numRemovedFiles='2', numUpdatedRows='2'), operationParameters=Row(predicate='(InvoiceNo#2648 = 563164)'), readVersion=2, timestamp=1598391134343), remove=None),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598391134125, path='part-00002-ae418f88-33ad-4119-9906-53feef7a5557-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598391134125, path='part-00000-ec6e161b-f530-4474-ab02-f0083d596f18-c000.snappy.parquet')),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391134000, path='part-00000-591907ef-834f-41f5-a7f5-35928ff8aefa-c000.snappy.parquet', size=322253), commitInfo=None, remove=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391134000, path='part-00001-8488bed6-f43f-4cd1-9053-79ccf4ec5f1a-c000.snappy.parquet', size=2369), commitInfo=None, remove=None)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Schema details: https://docs.delta.io/latest/delta-utility.html\n",
    "\n",
    "logDF = spark.read.format(\"json\").load(deltaLogPath + \"/00000000000000000003.json\")\n",
    "#dfLog.printSchema()\n",
    "logDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+--------------+\n",
      "|FileName                                                           |InvoiceNo|StockCode|Description                |Quantity|InvoiceDate     |UnitPrice|CustomerID|Country       |\n",
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+--------------+\n",
      "|part-00000-591907ef-834f-41f5-a7f5-35928ff8aefa-c000.snappy.parquet|563164   |23089    |GLASS BON BON JAR          |1144    |8/12/2011 12:18 |1.45     |16013     |United Kingdom|\n",
      "|part-00001-8488bed6-f43f-4cd1-9053-79ccf4ec5f1a-c000.snappy.parquet|563164   |2291     |WORLD'S BEST JAM MAKING SET|1005    |08/13/2011 07:58|1.45     |15358     |France        |\n",
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Before DML (delete)\n",
    "\n",
    "spark.sql(f\"\"\"select \n",
    "          substring(input_file_name(), -67, 67) as FileName,\n",
    "          * from SalesDeltaFormat \n",
    "          where InvoiceNo = {oneRandomInvoice}\"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/delta-io/delta/blob/master/examples/python/quickstart.py\n",
    "# Delete two records\n",
    "# This results in one new file being created.  One file had just the one record so it does not have to be re-created\n",
    "\n",
    "#T5A1T12\n",
    "spark.sql(f\"DELETE FROM SalesDeltaFormat WHERE InvoiceNo = {oneRandomInvoice}\")\n",
    "\n",
    "# deltaTable.delete(\n",
    "#    condition=(\"InvoiceNo = {537617}\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|FileName|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+--------+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "+--------+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After DML (delete)\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "              SELECT \n",
    "              SUBSTRING(input_file_name(), -67, 67) as FileName, *\n",
    "              FROM SalesDeltaFormat \n",
    "              WHERE InvoiceNo = {oneRandomInvoice}\n",
    "          \"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### HISTORY ########\n",
      "+---+---------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "|ver|operation|operationParameters                                                               |operationMetrics                                                                       |\n",
      "+---+---------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "|4  |DELETE   |[predicate -> [\"(spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = 563164)\"]]|[numRemovedFiles -> 2, numDeletedRows -> 2, numAddedFiles -> 1, numCopiedRows -> 29509]|\n",
      "|3  |UPDATE   |[predicate -> (InvoiceNo#2648 = 563164)]                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 2, numCopiedRows -> 29509]|\n",
      "|2  |WRITE    |[mode -> Append, partitionBy -> []]                                               |[numFiles -> 1, numOutputBytes -> 2369, numOutputRows -> 1]                            |\n",
      "|1  |WRITE    |[mode -> Append, partitionBy -> []]                                               |[numFiles -> 4, numOutputBytes -> 1125004, numOutputRows -> 99149]                     |\n",
      "|0  |WRITE    |[mode -> Overwrite, partitionBy -> []]                                            |[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]                     |\n",
      "+---+---------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"####### HISTORY ########\")\n",
    "\n",
    "# Observe history of actions taken on a Delta table\n",
    "history = deltaTable.history().select('version','operation', 'operationParameters', \\\n",
    "                                      'operationMetrics') \\\n",
    "                              .withColumnRenamed(\"version\", \"ver\")\n",
    "\n",
    "history.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195KB    2020-08-25 17:31:59  part-00003-8aedf44b-df4f-4194-8e0e-69b3790478ad-c000.snappy.parquet\n",
      "312KB    2020-08-25 17:32:00  part-00001-985a76da-9b3b-4b6d-8596-20fe7ee8e91d-c000.snappy.parquet\n",
      "282KB    2020-08-25 17:32:00  part-00000-023a68c6-9fc5-4f66-9163-7a517a09b2bc-c000.snappy.parquet\n",
      "314KB    2020-08-25 17:32:00  part-00002-8aafd9bb-16a7-4c09-aa34-f217d82cde16-c000.snappy.parquet\n",
      "193KB    2020-08-25 17:32:07  part-00003-fe773de7-76c0-4880-b4a5-e48275f6f25c-c000.snappy.parquet\n",
      "315KB    2020-08-25 17:32:07  part-00002-ae418f88-33ad-4119-9906-53feef7a5557-c000.snappy.parquet\n",
      "281KB    2020-08-25 17:32:08  part-00000-4d0d0177-abdf-48aa-8daf-62b696c3ed50-c000.snappy.parquet\n",
      "310KB    2020-08-25 17:32:08  part-00001-cb2d19ab-ac6a-4db7-974f-f7ebe111dc20-c000.snappy.parquet\n",
      "2KB      2020-08-25 17:32:11  part-00000-ec6e161b-f530-4474-ab02-f0083d596f18-c000.snappy.parquet\n",
      "2KB      2020-08-25 17:32:14  part-00001-8488bed6-f43f-4cd1-9053-79ccf4ec5f1a-c000.snappy.parquet\n",
      "315KB    2020-08-25 17:32:14  part-00000-591907ef-834f-41f5-a7f5-35928ff8aefa-c000.snappy.parquet\n",
      "315KB    2020-08-25 17:32:17  part-00000-4e88806c-a262-4b97-9226-d323b1d91c1f-c000.snappy.parquet\n",
      "\n",
      "Number of file/s: 12 | Total size: 2.9M\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaPath, \"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-25 17:32:01  00000000000000000000.json\n",
      "938B     2020-08-25 17:32:08  00000000000000000001.json\n",
      "410B     2020-08-25 17:32:11  00000000000000000002.json\n",
      "902B     2020-08-25 17:32:14  00000000000000000003.json\n",
      "775B     2020-08-25 17:32:17  00000000000000000004.json\n",
      "\n",
      "Number of file/s: 5 | Total size: 20K\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaLogPath,\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(add=None, commitInfo=Row(isBlindAppend=False, operation='DELETE', operationMetrics=Row(numAddedFiles='1', numCopiedRows='29509', numDeletedRows='2', numRemovedFiles='2'), operationParameters=Row(predicate='[\"(spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = 563164)\"]'), readVersion=3, timestamp=1598391137154), remove=None),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598391137152, path='part-00001-8488bed6-f43f-4cd1-9053-79ccf4ec5f1a-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598391137152, path='part-00000-591907ef-834f-41f5-a7f5-35928ff8aefa-c000.snappy.parquet')),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391137000, path='part-00000-4e88806c-a262-4b97-9226-d323b1d91c1f-c000.snappy.parquet', size=322959), commitInfo=None, remove=None)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logDF = spark.read.format(\"json\").load(deltaLogPath + \"/00000000000000000004.json\")\n",
    "#dfLog.printSchema()\n",
    "logDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomy update 5 records to force checkpoint\n",
    "\n",
    "#T6A11T23\n",
    "count = 0\n",
    "anInvoice = retailSalesData2.select(\"InvoiceNo\").orderBy(rand()).limit(1).collect()[0][0]\n",
    "\n",
    "while (count <= 5):\n",
    "  deltaTable.update(\n",
    "    condition=(f\"InvoiceNo = {anInvoice}\"),\n",
    "    set={\"Quantity\": expr(\"Quantity + 100\")})\n",
    "\n",
    "  count = count + 1\n",
    "  anInvoice = retailSalesData2.select(\"InvoiceNo\").orderBy(rand()).limit(1).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-25 17:32:01  00000000000000000000.json\n",
      "938B     2020-08-25 17:32:08  00000000000000000001.json\n",
      "410B     2020-08-25 17:32:11  00000000000000000002.json\n",
      "902B     2020-08-25 17:32:14  00000000000000000003.json\n",
      "775B     2020-08-25 17:32:17  00000000000000000004.json\n",
      "905B     2020-08-25 17:32:20  00000000000000000005.json\n",
      "905B     2020-08-25 17:32:22  00000000000000000006.json\n",
      "906B     2020-08-25 17:32:24  00000000000000000007.json\n",
      "905B     2020-08-25 17:32:26  00000000000000000008.json\n",
      "905B     2020-08-25 17:32:28  00000000000000000009.json\n",
      "905B     2020-08-25 17:32:30  00000000000000000010.json\n",
      "17KB     2020-08-25 17:32:32  00000000000000000010.checkpoint.parquet\n",
      "\n",
      "Number of file/s: 12 | Total size: 76K\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaLogPath,\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
      "|txn |add                                                                                                      |remove                                                                                     |metaData                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |protocol|commitInfo|\n",
      "+----+---------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
      "|null|null                                                                                                     |[part-00001-215f3a2a-2257-4e07-9e96-5fec997c58e3-c000.snappy.parquet, 1598391148344, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00002-8aafd9bb-16a7-4c09-aa34-f217d82cde16-c000.snappy.parquet, 1598391144359, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-0f5ee7b5-3c34-4409-b607-f162dba68ff3-c000.snappy.parquet, 1598391146503, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00001-8488bed6-f43f-4cd1-9053-79ccf4ec5f1a-c000.snappy.parquet, 1598391137152, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|[part-00001-b3586eaf-cffd-4c09-adee-0e939b5a9803-c000.snappy.parquet, [], 287563, 1598391148000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|[part-00000-c814697b-9d8f-4156-b1d3-b9c8fd2408ff-c000.snappy.parquet, [], 199821, 1598391140000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|[part-00001-ec7e0cd4-daf6-4bbf-885b-dfe7b4981007-c000.snappy.parquet, [], 197686, 1598391140000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-591907ef-834f-41f5-a7f5-35928ff8aefa-c000.snappy.parquet, 1598391137152, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00001-985a76da-9b3b-4b6d-8596-20fe7ee8e91d-c000.snappy.parquet, 1598391150487, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|[part-00000-898f4559-d69a-4808-b4a6-75a93bfa6ad2-c000.snappy.parquet, [], 288497, 1598391148000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|[part-00001-23973ef5-7cb7-45e7-bf78-482e85589eeb-c000.snappy.parquet, [], 320879, 1598391146000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-023a68c6-9fc5-4f66-9163-7a517a09b2bc-c000.snappy.parquet, 1598391142339, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|[part-00000-85bfdf53-6347-47e2-88c0-9789467c3db5-c000.snappy.parquet, [], 319769, 1598391150000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-4d0d0177-abdf-48aa-8daf-62b696c3ed50-c000.snappy.parquet, 1598391142339, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00002-ae418f88-33ad-4119-9906-53feef7a5557-c000.snappy.parquet, 1598391134125, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-2cfd682b-9382-4936-86bc-624af5523ae2-c000.snappy.parquet, 1598391148344, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|[part-00001-371ade99-e09c-4490-9d1f-011b0d874f99-c000.snappy.parquet, [], 317624, 1598391150000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00001-0d7fd546-186c-4927-85f9-dc39870faaf4-c000.snappy.parquet, 1598391146503, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00001-cb2d19ab-ac6a-4db7-974f-f7ebe111dc20-c000.snappy.parquet, 1598391150487, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |[1, 2]  |null      |\n",
      "|null|null                                                                                                     |null                                                                                       |[e1ff22de-5098-4cd6-9208-094028d347ab,,, [parquet, []], {\"type\":\"struct\",\"fields\":[{\"name\":\"InvoiceNo\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"StockCode\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Description\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Quantity\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"InvoiceDate\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"UnitPrice\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"CustomerID\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Country\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}, [], [], 1598391119308]|null    |null      |\n",
      "|null|[part-00000-04d154cf-f867-4fc0-a89c-bb6cb773d4ef-c000.snappy.parquet, [], 322991, 1598391146000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-4e88806c-a262-4b97-9226-d323b1d91c1f-c000.snappy.parquet, 1598391144359, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-ec6e161b-f530-4474-ab02-f0083d596f18-c000.snappy.parquet, 1598391134125, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00003-8aedf44b-df4f-4194-8e0e-69b3790478ad-c000.snappy.parquet, 1598391140157, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00003-fe773de7-76c0-4880-b4a5-e48275f6f25c-c000.snappy.parquet, 1598391140157, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "+----+---------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkPointDF = spark.read.format(\"parquet\").load(deltaLogPath + \"/00000000000000000010.checkpoint.parquet\")\n",
    "checkPointDF.show(100, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkPointFile10 =(\n",
    "    checkPointDF.select(col(\"add.path\").alias(\"FileAdded\"),\n",
    "                        col(\"add.modificationTime\").alias(\"DateAdded\"),\n",
    "                        col(\"remove.path\").alias(\"FileDeleted\"),\n",
    "                        col(\"remove.deletionTimestamp\").alias(\"DateDeleted\"))\n",
    "                .orderBy([\"DateAdded\",\"DateDeleted\"], ascending=[True,False])\n",
    ")\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS tbl_checkpointfile\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS tbl_checkpointfile (Action string, filename string, ActionDate Long)\")\n",
    "\n",
    "checkPointFile10.createOrReplaceTempView(\"vw_checkpointfile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+-------------+\n",
      "|FileAdded|DateAdded|         FileDeleted|  DateDeleted|\n",
      "+---------+---------+--------------------+-------------+\n",
      "|     null|     null|part-00001-985a76...|1598391150487|\n",
      "|     null|     null|part-00001-cb2d19...|1598391150487|\n",
      "|     null|     null|part-00001-215f3a...|1598391148344|\n",
      "|     null|     null|part-00000-2cfd68...|1598391148344|\n",
      "|     null|     null|part-00000-0f5ee7...|1598391146503|\n",
      "+---------+---------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from vw_checkpointfile limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          INSERT INTO tbl_checkpointfile\n",
    "          SELECT \"Add\", FileAdded, DateAdded\n",
    "          FROM vw_checkpointfile\n",
    "          WHERE FileAdded IS NOT NULL\n",
    "          \"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "          INSERT INTO tbl_checkpointfile\n",
    "          SELECT \"Delete\", FileDeleted, DateDeleted\n",
    "          FROM vw_checkpointfile\n",
    "          WHERE FileDeleted IS NOT NULL\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------------------------------------------------+-------------------+\n",
      "|Action|File Name                                                          |Action Date        |\n",
      "+------+-------------------------------------------------------------------+-------------------+\n",
      "|Delete|part-00002-ae418f88-33ad-4119-9906-53feef7a5557-c000.snappy.parquet|2020-08-25 17:32:14|\n",
      "|Delete|part-00000-ec6e161b-f530-4474-ab02-f0083d596f18-c000.snappy.parquet|2020-08-25 17:32:14|\n",
      "|Delete|part-00001-8488bed6-f43f-4cd1-9053-79ccf4ec5f1a-c000.snappy.parquet|2020-08-25 17:32:17|\n",
      "|Delete|part-00000-591907ef-834f-41f5-a7f5-35928ff8aefa-c000.snappy.parquet|2020-08-25 17:32:17|\n",
      "|Add   |part-00000-c814697b-9d8f-4156-b1d3-b9c8fd2408ff-c000.snappy.parquet|2020-08-25 17:32:20|\n",
      "|Add   |part-00001-ec7e0cd4-daf6-4bbf-885b-dfe7b4981007-c000.snappy.parquet|2020-08-25 17:32:20|\n",
      "|Delete|part-00003-8aedf44b-df4f-4194-8e0e-69b3790478ad-c000.snappy.parquet|2020-08-25 17:32:20|\n",
      "|Delete|part-00003-fe773de7-76c0-4880-b4a5-e48275f6f25c-c000.snappy.parquet|2020-08-25 17:32:20|\n",
      "|Delete|part-00000-023a68c6-9fc5-4f66-9163-7a517a09b2bc-c000.snappy.parquet|2020-08-25 17:32:22|\n",
      "|Delete|part-00000-4d0d0177-abdf-48aa-8daf-62b696c3ed50-c000.snappy.parquet|2020-08-25 17:32:22|\n",
      "|Delete|part-00002-8aafd9bb-16a7-4c09-aa34-f217d82cde16-c000.snappy.parquet|2020-08-25 17:32:24|\n",
      "|Delete|part-00000-4e88806c-a262-4b97-9226-d323b1d91c1f-c000.snappy.parquet|2020-08-25 17:32:24|\n",
      "|Add   |part-00001-23973ef5-7cb7-45e7-bf78-482e85589eeb-c000.snappy.parquet|2020-08-25 17:32:26|\n",
      "|Add   |part-00000-04d154cf-f867-4fc0-a89c-bb6cb773d4ef-c000.snappy.parquet|2020-08-25 17:32:26|\n",
      "|Delete|part-00000-0f5ee7b5-3c34-4409-b607-f162dba68ff3-c000.snappy.parquet|2020-08-25 17:32:26|\n",
      "|Delete|part-00001-0d7fd546-186c-4927-85f9-dc39870faaf4-c000.snappy.parquet|2020-08-25 17:32:26|\n",
      "|Add   |part-00001-b3586eaf-cffd-4c09-adee-0e939b5a9803-c000.snappy.parquet|2020-08-25 17:32:28|\n",
      "|Add   |part-00000-898f4559-d69a-4808-b4a6-75a93bfa6ad2-c000.snappy.parquet|2020-08-25 17:32:28|\n",
      "|Delete|part-00000-2cfd682b-9382-4936-86bc-624af5523ae2-c000.snappy.parquet|2020-08-25 17:32:28|\n",
      "|Delete|part-00001-215f3a2a-2257-4e07-9e96-5fec997c58e3-c000.snappy.parquet|2020-08-25 17:32:28|\n",
      "|Add   |part-00001-371ade99-e09c-4490-9d1f-011b0d874f99-c000.snappy.parquet|2020-08-25 17:32:30|\n",
      "|Add   |part-00000-85bfdf53-6347-47e2-88c0-9789467c3db5-c000.snappy.parquet|2020-08-25 17:32:30|\n",
      "|Delete|part-00001-985a76da-9b3b-4b6d-8596-20fe7ee8e91d-c000.snappy.parquet|2020-08-25 17:32:30|\n",
      "|Delete|part-00001-cb2d19ab-ac6a-4db7-974f-f7ebe111dc20-c000.snappy.parquet|2020-08-25 17:32:30|\n",
      "+------+-------------------------------------------------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "           SELECT Action, \n",
    "                  filename as `File Name`, \n",
    "                  from_unixtime(actiondate/1000) AS `Action Date`\n",
    "           FROM tbl_checkpointfile \n",
    "           order by ActionDate asc\n",
    "          \"\"\").show(200, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add some data to our table by doing a merge\n",
    "# Do this to show how json logs pick up after checkpoint\n",
    "\n",
    "#T7A4T27\n",
    "# Create a tiny dataframe to use with merge\n",
    "mergeSalesData= cleanSalesDataDF.sample(withReplacement=False, fraction=.0001, seed=13)\n",
    "mergeSalesData.createOrReplaceTempView(\"vw_mergeSalesData\")\n",
    "\n",
    "# User-defined commit metadata\n",
    "spark.sql(f\"\"\"\n",
    "               SET spark.databricks.delta.commitInfo.userMetadata=08-25-2020 Data Merge;\n",
    "          \"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "          MERGE INTO SalesDeltaFormat\n",
    "          USING vw_mergeSalesData\n",
    "          ON SalesDeltaFormat.StockCode = vw_mergeSalesData.StockCode\n",
    "           AND SalesDeltaFormat.InvoiceNo = vw_mergeSalesData.InvoiceNo\n",
    "          WHEN MATCHED THEN\n",
    "            UPDATE SET *\n",
    "          WHEN NOT MATCHED\n",
    "            THEN INSERT *\n",
    "          \"\"\")\n",
    "\n",
    "\n",
    "# Add to our Delta Lake table using retailSalesData2\n",
    "# tinyDataSample.write.mode(\"append\").format(\"delta\").save(deltaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### HISTORY ########\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ver|operation|operationParameters                                                                                                                                                                               |operationMetrics                                                                                                                                                                                                       |\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|11 |MERGE    |[predicate -> ((spark_catalog.deltademo.SalesDeltaFormat.`StockCode` = vw_mergesalesdata.`StockCode`) AND (spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = vw_mergesalesdata.`InvoiceNo`))]|[numTargetRowsCopied -> 198349, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 4, numTargetRowsInserted -> 26, numTargetRowsUpdated -> 25, numOutputRows -> 198400, numSourceRows -> 46, numTargetFilesRemoved -> 8]|\n",
      "|10 |UPDATE   |[predicate -> (InvoiceNo#1122 = 549681)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 14, numCopiedRows -> 54379]                                                                                                                               |\n",
      "|9  |UPDATE   |[predicate -> (InvoiceNo#1122 = 543389)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 10, numCopiedRows -> 50111]                                                                                                                               |\n",
      "|8  |UPDATE   |[predicate -> (InvoiceNo#1122 = 572676)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 26, numCopiedRows -> 58899]                                                                                                                               |\n",
      "|7  |UPDATE   |[predicate -> (InvoiceNo#1122 = 572552)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 157, numCopiedRows -> 58768]                                                                                                                              |\n",
      "|6  |UPDATE   |[predicate -> (InvoiceNo#1122 = 549250)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 47, numCopiedRows -> 50074]                                                                                                                               |\n",
      "|5  |UPDATE   |[predicate -> (InvoiceNo#1122 = 580504)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 39, numCopiedRows -> 34896]                                                                                                                               |\n",
      "|4  |DELETE   |[predicate -> [\"(spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = 563164)\"]]                                                                                                                |[numRemovedFiles -> 2, numDeletedRows -> 2, numAddedFiles -> 1, numCopiedRows -> 29509]                                                                                                                                |\n",
      "|3  |UPDATE   |[predicate -> (InvoiceNo#2648 = 563164)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 2, numCopiedRows -> 29509]                                                                                                                                |\n",
      "|2  |WRITE    |[mode -> Append, partitionBy -> []]                                                                                                                                                               |[numFiles -> 1, numOutputBytes -> 2369, numOutputRows -> 1]                                                                                                                                                            |\n",
      "|1  |WRITE    |[mode -> Append, partitionBy -> []]                                                                                                                                                               |[numFiles -> 4, numOutputBytes -> 1125004, numOutputRows -> 99149]                                                                                                                                                     |\n",
      "|0  |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]                                                                                                                                                     |\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"####### HISTORY ########\")\n",
    "\n",
    "# Observe history of actions taken on a Delta table\n",
    "history = deltaTable.history().select('version','operation', 'operationParameters', \\\n",
    "                                      'operationMetrics') \\\n",
    "                              .withColumnRenamed(\"version\", \"ver\")\n",
    "\n",
    "history.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-25 17:32:01  00000000000000000000.json\n",
      "938B     2020-08-25 17:32:08  00000000000000000001.json\n",
      "410B     2020-08-25 17:32:11  00000000000000000002.json\n",
      "902B     2020-08-25 17:32:14  00000000000000000003.json\n",
      "775B     2020-08-25 17:32:17  00000000000000000004.json\n",
      "905B     2020-08-25 17:32:20  00000000000000000005.json\n",
      "905B     2020-08-25 17:32:22  00000000000000000006.json\n",
      "906B     2020-08-25 17:32:24  00000000000000000007.json\n",
      "905B     2020-08-25 17:32:26  00000000000000000008.json\n",
      "905B     2020-08-25 17:32:28  00000000000000000009.json\n",
      "905B     2020-08-25 17:32:30  00000000000000000010.json\n",
      "17KB     2020-08-25 17:32:32  00000000000000000010.checkpoint.parquet\n",
      "2KB      2020-08-25 17:32:40  00000000000000000011.json\n",
      "\n",
      "Number of file/s: 13 | Total size: 80K\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaLogPath,\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(add=None, commitInfo=Row(isBlindAppend=False, operation='MERGE', operationMetrics=Row(numOutputRows='198400', numSourceRows='46', numTargetFilesAdded='4', numTargetFilesRemoved='8', numTargetRowsCopied='198349', numTargetRowsDeleted='0', numTargetRowsInserted='26', numTargetRowsUpdated='25'), operationParameters=Row(predicate='((spark_catalog.deltademo.SalesDeltaFormat.`StockCode` = vw_mergesalesdata.`StockCode`) AND (spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = vw_mergesalesdata.`InvoiceNo`))'), readVersion=10, timestamp=1598391160122, userMetadata='08-25-2020 Data Merge;'), remove=None),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598391160117, path='part-00000-04d154cf-f867-4fc0-a89c-bb6cb773d4ef-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598391160121, path='part-00000-898f4559-d69a-4808-b4a6-75a93bfa6ad2-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598391160121, path='part-00000-85bfdf53-6347-47e2-88c0-9789467c3db5-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598391160121, path='part-00001-ec7e0cd4-daf6-4bbf-885b-dfe7b4981007-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598391160121, path='part-00000-c814697b-9d8f-4156-b1d3-b9c8fd2408ff-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598391160121, path='part-00001-b3586eaf-cffd-4c09-adee-0e939b5a9803-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598391160121, path='part-00001-23973ef5-7cb7-45e7-bf78-482e85589eeb-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598391160121, path='part-00001-371ade99-e09c-4490-9d1f-011b0d874f99-c000.snappy.parquet')),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391160000, path='part-00000-d3444b69-81f9-4e4c-b4b1-d05cef4aabf7-c000.snappy.parquet', size=563138), commitInfo=None, remove=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391160000, path='part-00001-a662093a-2525-4ff7-b118-740d3c70ca46-c000.snappy.parquet', size=561684), commitInfo=None, remove=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391160000, path='part-00002-74b9c160-2b84-4ab4-a9bb-36c0f37ac2e5-c000.snappy.parquet', size=562143), commitInfo=None, remove=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598391160000, path='part-00003-0447e049-cc4f-43ec-aed3-939f1dfa6a9f-c000.snappy.parquet', size=558107), commitInfo=None, remove=None)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logDF = spark.read.format(\"json\").load(deltaLogPath + \"/00000000000000000011.json\")\n",
    "#dfLog.printSchema()\n",
    "logDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are ['29'] files.\n"
     ]
    }
   ],
   "source": [
    "# Count files in deltaPath\n",
    "\n",
    "numFiles = ! ls $deltaPath | wc -l\n",
    "print(f\"There are {numFiles} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta Lake File Compaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an artificial \"small file\" problem\n",
    "\n",
    "(spark.read\n",
    ".format(\"delta\")\n",
    ".load(deltaPath)\n",
    ".repartition(1000)\n",
    ".write\n",
    ".option(\"dataChange\", True)\n",
    ".format(\"delta\")\n",
    ".mode(\"overwrite\")\n",
    ".save(deltaPath)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are ['1029'] files.\n"
     ]
    }
   ],
   "source": [
    "# Count files in deltaPath\n",
    "\n",
    "numFiles = ! ls $deltaPath | wc -l\n",
    "print(f\"There are {numFiles} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count => 4244\n",
      "\n",
      "CPU times: user 2.14 ms, sys: 1.82 ms, total: 3.96 ms\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# spark.sql(\"select * from SalesDeltaFormat limit 2\").show()\n",
    "\n",
    "rowCount = spark.sql(\"\"\" SELECT CustomerID, count(Country) AS num_countries\n",
    "                         FROM SalesDeltaFormat\n",
    "                         GROUP BY CustomerID \n",
    "                     \"\"\").count()\n",
    "\n",
    "print(f\"Row Count => {rowCount}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compact 1000 files to 4\n",
    "\n",
    "(spark.read\n",
    ".format(\"delta\")\n",
    ".load(deltaPath)\n",
    ".repartition(4)\n",
    ".write\n",
    ".option(\"dataChange\", False)\n",
    ".format(\"delta\")\n",
    ".mode(\"overwrite\")\n",
    ".save(deltaPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are ['1033'] files.\n"
     ]
    }
   ],
   "source": [
    "# Count files in deltaPath\n",
    "\n",
    "numFiles = ! ls $deltaPath | wc -l\n",
    "print(f\"There are {numFiles} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count => 4244\n",
      "CPU times: user 2.06 ms, sys: 1.78 ms, total: 3.84 ms\n",
      "Wall time: 272 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# spark.sql(\"select * from SalesDeltaFormat limit 2\").show()\n",
    "rowCount = spark.sql(\"\"\" select CustomerID, count(Country) as num_countries\n",
    "                         from SalesDeltaFormat\n",
    "                        group by CustomerID \"\"\").count()\n",
    "\n",
    "print(f\"Row Count => {rowCount}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta Time Travel Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count: 198400 as of table version 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time Travel Queries\n",
    "\n",
    "#POO currentVersion = deltaTable.history(1).select(\"version\").collect()[0][0]\n",
    "# Determine latest version of the Delta table\n",
    "currentVersion = spark.sql(\"DESCRIBE HISTORY SalesDeltaFormat LIMIT 1\").collect()[0][0]\n",
    "\n",
    "# Query table as of the current version to attain row count\n",
    "currentRowCount = spark.read.format(\"delta\").option(\"versionAsOf\", currentVersion).load(deltaPath).count()\n",
    "\n",
    "print(f\"Row Count: {currentRowCount} as of table version {currentVersion}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### HISTORY ########\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ver|operation|operationParameters                                                                                                                                                                               |operationMetrics                                                                                                                                                                                                       |\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|13 |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 4, numOutputBytes -> 2966700, numOutputRows -> 198400]                                                                                                                                                    |\n",
      "|12 |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 1000, numOutputBytes -> 11377506, numOutputRows -> 198400]                                                                                                                                                |\n",
      "|11 |MERGE    |[predicate -> ((spark_catalog.deltademo.SalesDeltaFormat.`StockCode` = vw_mergesalesdata.`StockCode`) AND (spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = vw_mergesalesdata.`InvoiceNo`))]|[numTargetRowsCopied -> 198349, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 4, numTargetRowsInserted -> 26, numTargetRowsUpdated -> 25, numOutputRows -> 198400, numSourceRows -> 46, numTargetFilesRemoved -> 8]|\n",
      "|10 |UPDATE   |[predicate -> (InvoiceNo#1122 = 549681)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 14, numCopiedRows -> 54379]                                                                                                                               |\n",
      "|9  |UPDATE   |[predicate -> (InvoiceNo#1122 = 543389)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 10, numCopiedRows -> 50111]                                                                                                                               |\n",
      "|8  |UPDATE   |[predicate -> (InvoiceNo#1122 = 572676)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 26, numCopiedRows -> 58899]                                                                                                                               |\n",
      "|7  |UPDATE   |[predicate -> (InvoiceNo#1122 = 572552)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 157, numCopiedRows -> 58768]                                                                                                                              |\n",
      "|6  |UPDATE   |[predicate -> (InvoiceNo#1122 = 549250)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 47, numCopiedRows -> 50074]                                                                                                                               |\n",
      "|5  |UPDATE   |[predicate -> (InvoiceNo#1122 = 580504)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 39, numCopiedRows -> 34896]                                                                                                                               |\n",
      "|4  |DELETE   |[predicate -> [\"(spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = 563164)\"]]                                                                                                                |[numRemovedFiles -> 2, numDeletedRows -> 2, numAddedFiles -> 1, numCopiedRows -> 29509]                                                                                                                                |\n",
      "|3  |UPDATE   |[predicate -> (InvoiceNo#2648 = 563164)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 2, numCopiedRows -> 29509]                                                                                                                                |\n",
      "|2  |WRITE    |[mode -> Append, partitionBy -> []]                                                                                                                                                               |[numFiles -> 1, numOutputBytes -> 2369, numOutputRows -> 1]                                                                                                                                                            |\n",
      "|1  |WRITE    |[mode -> Append, partitionBy -> []]                                                                                                                                                               |[numFiles -> 4, numOutputBytes -> 1125004, numOutputRows -> 99149]                                                                                                                                                     |\n",
      "|0  |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]                                                                                                                                                     |\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"####### HISTORY ########\")\n",
    "\n",
    "# Observe history of actions taken on a Delta table\n",
    "history = deltaTable.history().select('version','operation', 'operationParameters', \\\n",
    "                                      'operationMetrics') \\\n",
    "                              .withColumnRenamed(\"version\", \"ver\")\n",
    "\n",
    "history.show(100, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 99174 more rows in version [13] than version [0] of the table.\n"
     ]
    }
   ],
   "source": [
    "# Determine difference in record count between the current version and the original version of the table.\n",
    "\n",
    "origRowCount = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(deltaPath).count()\n",
    "print(f\"There are {currentRowCount-origRowCount} more rows in version [{currentVersion}] than version [0] of the table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roll back current table to version 0 (original).\n",
    "(\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"delta\")\n",
    "    .option(\"versionAsOf\",0)\n",
    "    .load(deltaPath)\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(deltaPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current version should have same record count as version 0.\n",
    "\n",
    "currentVersion = spark.sql(\"DESCRIBE HISTORY SalesDeltaFormat LIMIT 1\").collect()[0][0]\n",
    "# If equal it will return \"true\"\n",
    "spark.read.format(\"delta\").option(\"versionAsOf\", currentVersion).load(deltaPath).count() == spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(deltaPath).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### HISTORY ########\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ver|operation|operationParameters                                                                                                                                                                               |operationMetrics                                                                                                                                                                                                       |\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|14 |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]                                                                                                                                                     |\n",
      "|13 |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 4, numOutputBytes -> 2966700, numOutputRows -> 198400]                                                                                                                                                    |\n",
      "|12 |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 1000, numOutputBytes -> 11377506, numOutputRows -> 198400]                                                                                                                                                |\n",
      "|11 |MERGE    |[predicate -> ((spark_catalog.deltademo.SalesDeltaFormat.`StockCode` = vw_mergesalesdata.`StockCode`) AND (spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = vw_mergesalesdata.`InvoiceNo`))]|[numTargetRowsCopied -> 198349, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 4, numTargetRowsInserted -> 26, numTargetRowsUpdated -> 25, numOutputRows -> 198400, numSourceRows -> 46, numTargetFilesRemoved -> 8]|\n",
      "|10 |UPDATE   |[predicate -> (InvoiceNo#1122 = 549681)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 14, numCopiedRows -> 54379]                                                                                                                               |\n",
      "|9  |UPDATE   |[predicate -> (InvoiceNo#1122 = 543389)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 10, numCopiedRows -> 50111]                                                                                                                               |\n",
      "|8  |UPDATE   |[predicate -> (InvoiceNo#1122 = 572676)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 26, numCopiedRows -> 58899]                                                                                                                               |\n",
      "|7  |UPDATE   |[predicate -> (InvoiceNo#1122 = 572552)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 157, numCopiedRows -> 58768]                                                                                                                              |\n",
      "|6  |UPDATE   |[predicate -> (InvoiceNo#1122 = 549250)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 47, numCopiedRows -> 50074]                                                                                                                               |\n",
      "|5  |UPDATE   |[predicate -> (InvoiceNo#1122 = 580504)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 39, numCopiedRows -> 34896]                                                                                                                               |\n",
      "|4  |DELETE   |[predicate -> [\"(spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = 563164)\"]]                                                                                                                |[numRemovedFiles -> 2, numDeletedRows -> 2, numAddedFiles -> 1, numCopiedRows -> 29509]                                                                                                                                |\n",
      "|3  |UPDATE   |[predicate -> (InvoiceNo#2648 = 563164)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 2, numCopiedRows -> 29509]                                                                                                                                |\n",
      "|2  |WRITE    |[mode -> Append, partitionBy -> []]                                                                                                                                                               |[numFiles -> 1, numOutputBytes -> 2369, numOutputRows -> 1]                                                                                                                                                            |\n",
      "|1  |WRITE    |[mode -> Append, partitionBy -> []]                                                                                                                                                               |[numFiles -> 4, numOutputBytes -> 1125004, numOutputRows -> 99149]                                                                                                                                                     |\n",
      "|0  |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]                                                                                                                                                     |\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"####### HISTORY ########\")\n",
    "\n",
    "# Observe history of actions taken on a Delta table\n",
    "history = deltaTable.history().select('version','operation', 'operationParameters', \\\n",
    "                                      'operationMetrics') \\\n",
    "                              .withColumnRenamed(\"version\", \"ver\")\n",
    "\n",
    "history.show(100, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta Vacuum - Data Retention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delta.logRetentionDuration - default 30 days\n",
    "<br>\n",
    "delta.deletedFileRetentionDuration - default 30 days\n",
    "\n",
    "* Don't need to set them to be the same.  You may want to keep the log files around after the tombstoned files are purged.\n",
    "* Time travel in order of months/years infeasible\n",
    "* Initially desinged to correct mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are ['1037'] files.\n"
     ]
    }
   ],
   "source": [
    "# files_in_dir(deltaPath,\"parquet\")\n",
    "# Count files in deltaPath\n",
    "\n",
    "numFiles = ! ls $deltaPath | wc -l\n",
    "print(f\"There are {numFiles} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Are you sure you would like to vacuum files with such a low retention period? If you have\nwriters that are currently writing to this table, there is a risk that you may corrupt the\nstate of your Delta table.\n\nIf you are certain that there are no operations being performed on this table, such as\ninsert/upsert/delete/optimize, then you may turn off this check by setting:\nspark.databricks.delta.retentionDurationCheck.enabled = false\n\nIf you are not sure, please use a value not less than \"168 hours\".\n       ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-cf051bf871e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Attempt to vacuum table with default settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vacuum SalesDeltaFormat retain 0 hours dry run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \"\"\"\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Are you sure you would like to vacuum files with such a low retention period? If you have\nwriters that are currently writing to this table, there is a risk that you may corrupt the\nstate of your Delta table.\n\nIf you are certain that there are no operations being performed on this table, such as\ninsert/upsert/delete/optimize, then you may turn off this check by setting:\nspark.databricks.delta.retentionDurationCheck.enabled = false\n\nIf you are not sure, please use a value not less than \"168 hours\".\n       "
     ]
    }
   ],
   "source": [
    "# Attempt to vacuum table with default settings\n",
    "\n",
    "spark.sql(\"vacuum SalesDeltaFormat retain 0 hours dry run\").show(100, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Vacuum Delta table to remove all history\n",
    "\n",
    "spark.sql(\"VACUUM SalesDeltaFormat RETAIN 0 HOURS\").show(truncate = False)\n",
    "# ! Can use deltaTable.vacuum(0) against directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_dir(deltaPath,\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_dir(deltaLogPath,\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"json\").load(deltaLogPath + \"/00000000000000000014.json\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"delta\").option(\"versionAsOf\", currentVersion).load(deltaPath).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Delta table to keep around 7 days of deleted data and 7 days of older log files\n",
    "spark.sql(\"alter table SalesDeltaFormat set tblproperties ('delta.logRetentionDuration' = 'interval 7 days', 'delta.deletedFileRetentionDuration' = 'interval 7 days')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify our changes\n",
    "spark.sql(\"describe extended SalesDeltaFormat\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
